\section{Conclusion}

\subsection{Achievements}
\textit{Andrei P.}\\
We remind the reader that we defined our goals for this project as follows:
\begin{itemize}
    \item \textbf{To implement a method for musical style transfer and conditional generation using latent diffusion models.}: In this regard our results demonstrate the potential of LDMs for audio style transfer and provide a foundation for future research. While there are limitations, and that is mainly due to the complex training and computational requirements, we believe the existing unmodified code based would provide better results with significantly more training (we estimate that around 60 GPU hours of A100 would meet the requirement).
    \item \textbf{To show that the method works for a variety of musical styles and instruments.}: The style transfer capabilities of our model remain unclear (\textit{that is we the style conditioned generated spectrograms look blurry (see Figures X and Y) and that can be attributed both to insufficient denoising and to poor interpolation of style, which may suggest the style network is not learning relevant style characteristics}). Since the produced results may be invalid because of the limited training, we cannot indicate for certain that the style transfer is not successful. We do believe that the style transfer may be problematic, and this is illustrated by the almost constant style loss, but further investigation is required.
    \item \textbf{To show that the model is able to understand tonal characteristics of different instruments.}: This objective was not achieved, we were not able to assess in any way the tonal characteristics of the generated spectrograms or see any noticeable difference between the generated spectrograms of different instruments.
\end{itemize}

\vspace{0.5cm}


\noindent We tackled a new problem with little available resources, which combines both audio and image processing. We were thus able to expand our knowledge in both fields which we consider a success of this project. While there are limitations and areas for improvement, the results demonstrate the potential of LDMs for audio style transfer and provide a foundation for future research in this direction. 

\subsection{Future Work}
\textit{Andrei P.}\\
Given more resources, we would like to explore the following directions:
\begin{itemize}
    \item \textbf{Increase the number of parameters and training time}: The current model is relatively small, having only 12M parameters. We wish to try a bigger model, but that would require even more training time.
    \item \textbf{Augment the dataset}: At this point a random noise level is generated per each sample of the dataset, hoping that our model will learn to denoise at all noise levels. We considered augmenting the dataset, by training the model for each sample at multiple noise levels, but this increased the training effort substantially (by a factor of 100). This was not feasible given our previous resources.
    \item \textbf{Different style loss}: We would research for different style loss functions, and try to find pretrained models that work better on spectrograms.
    \item \textbf{Changes to noise scheduler and embedding}: We would experiment with a different noise scheduler and embedding mechanism to see if it improves results.
    \item \textbf{Embed labels into the loss}: Since we have information about the instrument being played, we could perhaps embed this into the loss calculation, in the same way they do in CLIPs\footnote{Learning Transferable Visual Models From Natural Language Supervision~\cite{radford2021learning}}. This could increase the capability of the model of style transfer.
\end{itemize}

